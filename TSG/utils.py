import torch
import torch.nn as nn

class AverageMeter(object):
    """
    Keeps track of most recent, average, sum, and count of a metric.
    """

    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

def clip_gradient(optimizer, grad_clip):
    """
    Clips gradients computed during backpropagation to avoid explosion of gradients.

    :param optimizer: optimizer with the gradients to be clipped
    :param grad_clip: clip value
    """
    for group in optimizer.param_groups:
        for param in group['params']:
            if param.grad is not None:
                param.grad.data.clamp_(-grad_clip, grad_clip)

def adjust_learning_rate(optimizer, shrink_factor):
    """
    Shrinks learning rate by a specified factor.

    :param optimizer: optimizer whose learning rate must be shrunk.
    :param shrink_factor: factor in interval (0, 1) to multiply learning rate with.
    """
    print("\nDECAYING learning rate.")
    for param_group in optimizer.param_groups:
        param_group['lr'] = param_group['lr'] * shrink_factor
    print("The new learning rate is %f\n" % (optimizer.param_groups[0]['lr'],))

def save_checkpoint(save_dir, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer, decoder_optimizer,
                    loss, is_best):
    """
    Saves model checkpoint.
    :param save_dir: store checkpoints here
    :param epoch: epoch number
    :param epochs_since_improvement: number of epochs since last improvement in BLEU-4 score
    :param encoder: encoder model
    :param decoder: decoder model
    :param encoder_optimizer: optimizer to update encoder's weights, if fine-tuning
    :param decoder_optimizer: optimizer to update decoder's weights
    :param loss: validation loss score for this epoch
    :param is_best: is this checkpoint the best so far?
    """
    state = {'epoch': epoch,
             'epochs_since_improvement': epochs_since_improvement,
             'testLoss': loss,
             'encoder': encoder,
             'decoder': decoder,
             'encoder_optimizer': encoder_optimizer,
             'decoder_optimizer': decoder_optimizer}
    filename = save_dir +'checkpoint_' + 'epoch_' + str(epoch) + '_loss:{:.2f}'.format(loss) + '.pth'
    torch.save(state, filename)
    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint
    if is_best:
        filename = save_dir +'checkpoint_' + 'best.pth'
        torch.save(state, filename)
        
def cal_direction(point):
    '''
    give out the closest direction of the sequnce final point
    :param: point should be a list
    :output: direction dim = 4
        x+y   | x-y | direction
        +     | +   | 3  right
        +     | -   | 2  up
        -     | +   | 0  below
        -     | -   | 1  left
    '''
    a = point[0] + point[1]
    b = point[0] - point[1]

    if a > 0 and b > 0:
        di = 3
    elif a > 0 and b <= 0:
        di = 2
    elif a <= 0 and b > 0:
        di = 0
    else:
        di = 1
    direction = [0,0,0,0]
    direction[di] = 1
    return direction

def move_forward(pred_inv, seq_lens, device):
    '''
    move inverse predictions forward to match normally ordered prediction
    :param pred_inv: tensor generated by inverse lstm, (b, max_len, 2)
    :param seq_len: tensor indicate the length of each sequence in the batch, (b)
    '''
    cache = torch.zeros(pred_inv.shape).to(device)
    b, max_len, _ = pred_inv.shape # batch size
    for i in range(b):
        seq_len = seq_lens[i].item()
        cache[i,:seq_len+1,:] = pred_inv[i,max_len - seq_len - 1:,:]
    
    return cache

class traj_loss(nn.Module):
    def __init__(self, size_average=None, reduce=None, reduction='mean'):
        super(traj_loss, self).__init__()
        self.criterion = nn.MSELoss(size_average,reduce,reduction)

    def forward(self, pred, target):
        target = target[:,:,:]
        length = pred.size(1)
        # w = e ^ (1 - index / length)
        # 
        weight = torch.tensor([(length-i)/length for i in range(length)])
        weight = torch.exp(weight)
        weight /= weight.sum()
        # 每一个点分别算mse，之后累加得到加权loss
        loss = self.criterion(pred[:,0,:], target[:,0,:])*weight[0]
        for n in range(1, length):
            loss = loss + self.criterion(pred[:,n,:], target[:,n,:])*weight[n]
        loss /= length
        return loss